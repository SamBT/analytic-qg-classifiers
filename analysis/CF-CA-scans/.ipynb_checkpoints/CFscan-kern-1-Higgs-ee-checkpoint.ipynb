{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import uproot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# energyflow imports\n",
    "import energyflow as ef\n",
    "from energyflow.archs import *\n",
    "from energyflow.utils import data_split, remap_pids, to_categorical\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2gg_dir = '/home/sambt/pythia-samples/optimal-classifiers/H2gg-ee/'\n",
    "h2qq_dir = '/home/sambt/pythia-samples/optimal-classifiers/H2qqbar-ee/'\n",
    "kern = -1\n",
    "#CFs = [0.0001,1/3,2/3,1,4/3,5/3,2,7/3,8/3,3]\n",
    "CFs = [4/3]\n",
    "CA = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.19879227,  2.72662809,  4.27254895,  7.4201559 ,  9.65858289,\n",
       "        9.65858289,  3.70542392,  5.01987503,  4.76586242,  4.76586242,\n",
       "        3.42240189, 17.53696167, 15.0663135 , 33.60739495, 33.60739495,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = uproot.open(h2qq_dir+'kernel-1/H2qqbar-ee-100k_CF_0.7_CA_3.0/total.root')['EventTree']\n",
    "gjet_pt = f.array('plead_constit_pt')\n",
    "gjet_pt[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "Weights sum to zero, can't be normalized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-4813c00b4cf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0myphi_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0myphi_avg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36maverage\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/sambt-uproot/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscl\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             raise ZeroDivisionError(\n\u001b[0;32m--> 423\u001b[0;31m                 \"Weights sum to zero, can't be normalized\")\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mscl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: Weights sum to zero, can't be normalized"
     ]
    }
   ],
   "source": [
    "for CF in CFs:\n",
    "    fname_gg = 'kernel{0}/H2gg-ee-100k_CF_{1:.1f}_CA_{2:.1f}/total.root'.format(kern,CF,CA)\n",
    "    fname_qq = 'kernel{0}/H2qqbar-ee-100k_CF_{1:.1f}_CA_{2:.1f}/total.root'.format(kern,CF,CA)\n",
    "    \n",
    "    f_gg = uproot.open(h2gg_dir+fname_gg)['EventTree']\n",
    "    f_qq = uproot.open(h2qq_dir+fname_qq)['EventTree']\n",
    "    nev_gg = f_gg.numentries\n",
    "    nev_qq = f_qq.numentries\n",
    "    \n",
    "    gjet_pt = f_gg.array(\"plead_constit_pt\")\n",
    "    gjet_eta = f_gg.array(\"plead_constit_eta\")\n",
    "    gjet_phi = f_gg.array(\"plead_constit_phi\")\n",
    "\n",
    "    qjet_pt = f_qq.array(\"plead_constit_pt\")\n",
    "    qjet_eta = f_qq.array(\"plead_constit_eta\")\n",
    "    qjet_phi = f_qq.array(\"plead_constit_phi\")\n",
    "    \n",
    "    #remove events where there is no leading quark or gluon jet for some reason\n",
    "    #gjet_pt = gjet_pt[gjet_pt.any()]\n",
    "    #gjet_eta = gjet_eta[gjet_eta.any()]\n",
    "    #gjet_phi = gjet_phi[gjet_phi.any()]\n",
    "\n",
    "    #qjet_pt = qjet_pt[qjet_pt.any()]\n",
    "    #qjet_eta = qjet_eta[qjet_eta.any()]\n",
    "    #qjet_phi = qjet_phi[qjet_phi.any()]\n",
    "    \n",
    "    pad_size = 100\n",
    "    \n",
    "    quarks = np.array([[[qjet_pt[i,j],qjet_eta[i,j],qjet_phi[i,j]] for j in range(pad_size)] for i in range(nev_qq)])\n",
    "    gluons = np.array([[[gjet_pt[i,j],gjet_eta[i,j],gjet_phi[i,j]] for j in range(pad_size)] for i in range(nev_gg)])\n",
    "    \n",
    "    #make vectors with truth labels, combine q & g samples, shuffle\n",
    "    quark_labs = np.ones(np.size(quarks,axis=0))\n",
    "    glu_labs = np.zeros(np.size(gluons,axis=0))\n",
    "\n",
    "    X = np.concatenate((quarks,gluons))\n",
    "    y = np.concatenate((quark_labs,glu_labs))\n",
    "\n",
    "    shuf = np.arange(np.size(X,axis=0))\n",
    "    np.random.shuffle(shuf)\n",
    "\n",
    "    X = X[shuf]\n",
    "    y = y[shuf]\n",
    "    \n",
    "    #network parameters\n",
    "    train, test, val = 75000, 40000, 60000\n",
    "    Phi_sizes, F_sizes = (100, 100, 128), (100, 100, 100)\n",
    "    num_epoch = 5\n",
    "    batch_size = 500\n",
    "\n",
    "    #convert quark/gluon labels to categorical\n",
    "    Y = to_categorical(y,num_classes=2)\n",
    "    \n",
    "    # preprocess by centering jets and normalizing pts\n",
    "    for x in X:\n",
    "        mask = x[:,0] > 0\n",
    "        yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "        x[mask,1:3] -= yphi_avg\n",
    "        x[mask,0] /= x[:,0].sum()\n",
    "\n",
    "    print('Finished preprocessing')\n",
    "    \n",
    "    # do train/val/test split \n",
    "    (X_train, X_val, X_test,\n",
    "     Y_train, Y_val, Y_test) = data_split(X, Y, val=val, test=test)\n",
    "\n",
    "    print('Done train/val/test split')\n",
    "    \n",
    "    print('Model summary:')\n",
    "\n",
    "    # build architecture\n",
    "    pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)\n",
    "\n",
    "    # train model\n",
    "    pfn.fit(X_train, Y_train,\n",
    "              epochs=num_epoch,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(X_val, Y_val),\n",
    "              verbose=1)\n",
    "\n",
    "    # get predictions on test data\n",
    "    preds = pfn.predict(X_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sambt-uproot",
   "language": "python",
   "name": "sambt-uproot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
