{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../utils/\")\n",
    "from train_tools import train_qg_pfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded files at 0.5507175922393799\n",
      "Read in arrays at 26.896541357040405\n",
      "Limited max events at 26.89664602279663\n",
      "Cleaned events at 28.437063932418823\n",
      "qmaxmult = 13, gmaxmult = 15\n",
      "Made quark/gluon input arrays at 82.99613642692566\n",
      "Finished preprocessing at 209.96179461479187\n",
      "Done train/val/test split at 210.8699507713318\n",
      "Model summary:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 3)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    400         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 128)          0           mask[0][0]                       \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 100)          12900       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 100)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_0_dropout (Dropout)       (None, 100)          0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          10100       dense_0_dropout[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1_dropout (Dropout)       (None, 100)          0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          10100       dense_1_dropout[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 100)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2_dropout (Dropout)       (None, 100)          0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            202         dense_2_dropout[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 56,730\n",
      "Trainable params: 56,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1383386 samples, validate on 296440 samples\n",
      "Epoch 1/3\n",
      "1383386/1383386 [==============================] - 22s 16us/step - loss: 0.6412 - acc: 0.6358 - val_loss: 0.6351 - val_acc: 0.6422\n",
      "Epoch 2/3\n",
      "1383386/1383386 [==============================] - 22s 16us/step - loss: 0.6353 - acc: 0.6412 - val_loss: 0.6298 - val_acc: 0.6477\n",
      "Epoch 3/3\n",
      "1383386/1383386 [==============================] - 22s 16us/step - loss: 0.6319 - acc: 0.6453 - val_loss: 0.6257 - val_acc: 0.6532\n",
      "Finished training at 277.50461530685425\n",
      "\n",
      "PFN AUC: 0.7055511114828463\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/home/sambt/pythia83-samples/optimal-classifiers/kernel-1/\"\n",
    "fname_gg = base_dir+'H2gg-1M-CF1.3CA3.0/total.root'\n",
    "fname_qq = base_dir+'H2qq-1M-CF1.3CA3.0/total.root'\n",
    "\n",
    "output = train_qg_pfn(fname_qq,fname_gg,nev_max=1000000,n_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sambt-uproot",
   "language": "python",
   "name": "sambt-uproot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
